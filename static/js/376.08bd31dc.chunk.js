"use strict";(self.webpackChunkvickraj_website=self.webpackChunkvickraj_website||[]).push([[376],{8376:function(e,t,a){a.r(t),a.d(t,{default:function(){return p}});var i=a(2791),n=JSON.parse('{"TN":"Target Domain Data Induces Negative Transfer in Multi Source Classification under Category Shift","v":"Eryk Banatt, Vickram Rajendran*","kQ":"Multi-Source Domain Adaptation is traditionally framed such that each source domain has examples from every category, and each source domain is different from the target domain. However, in practical scenarios, it is often the case that the available training data within the target domain only exist for a limited number of classes, with the remaining classes only available within surrogate domains. We show that including the target domain in training when there exist disjoint classes between the target and surrogate domains creates significant negative transfer, and causes performance to significantly decrease compared to training without the target domain at all. We hypothesize that this negative transfer is due to decision-tree-like behavior in earlier layers of the neural networks that only occurs when multiple source domains are present, and provide experimental evidence that this may be the case. We show that this phenomena occurs on over 25 distinct domain shifts, both synthetic and real, and in many cases deteriorates the performance to well worse than random.","p4":[],"RL":"Preprint. Under Review","qv":"negative_transfer_fig1.png"}'),o=JSON.parse('{"TN":"Shape-Biased Domain Generalization via Shock Graph Embeddings","v":"Maruthi Narayanan, Vickram Rajendran, Benjamin Kimia","kQ":"There is an emerging sense that the vulnerability of Image Convolutional Neural Networks (CNN), i.e., sensitivity to image corruptions, perturbations, and adversarial attacks, is connected with Texture Bias. This relative lack of Shape Bias is also responsible for poor performance in Domain Generalization (DG). The inclusion of a role of shape alleviates these vulnerabilities and some approaches have achieved this by training on negative images, images endowed with edge maps, or images with conflicting shape and texture information. This paper advocates an explicit and complete representation of shape using classical computer vision approach, namely, representing the shape content of an image with the shock graph of its contour map. The resulting graph and its descriptor is a complete representation of contour content and is classified using recent Graph Neural Network (GNN) methods. The experimental results on three domain shift datasets, Colored MNIST, PACS, and VLCS demonstrate that even without using appearance the shape-based approach exceeds classical Image CNN based methods in domain generalization.","p4":[{"title":"Paper","href":"https://arxiv.org/abs/2109.05671"}],"RL":"Accepted to the proceedings of ICCV 2021.","qv":"shape_bias.png"}'),r=JSON.parse('{"TN":"Accurate Layerwise Interpretable Competence Estimation","v":"Vickram Rajendran, William LeVine","kQ":"Estimating machine learning performance \'in the wild\' is both an important and unsolved problem. In this paper, we seek to examine, understand, and predict the pointwise competence of classification models. Our contributions are twofold - First, we establish a statistically rigorous definition of competence that generalizes the common notion of classifier confidence; second, we present the ALICE (Accurate Layerwise Interpretable Competence Estimation) Score, a pointwise competence estimator for any classifier. By considering distributional, data, and model uncertainty, ALICE empirically shows accurate competence estimation in common failure situations such as class-imbalanced datasets, out-of-distribution datasets, and poorly trained models. Our contributions allow us to accurately predict the competence of any classification model given any input and error function. We compare our score with state-of-the-art confidence estimators such as model confidence and Trust Score, and show significant improvements in competence prediction over these methods on datasets such as DIGITS, CIFAR10, and CIFAR100.","p4":[{"title":"Paper","href":"https://arxiv.org/abs/1910.11363"},{"title":"Article","href":"https://www.jhuapl.edu/PressRelease/191029"},{"title":"Slides","href":"https://github.com/vickraj/ALICE"}],"RL":"Accepted to the proceedings of NeurIPS 2019.","qv":"alice_view.png"}'),s=JSON.parse('{"TN":" Jabberwocky - Question Answering with Pseudowords","v":"Vickram Rajendran, Eryk Banatt*","kQ":" We show that Large Language Models (LLM\'s) that train on internet-scale data fail dramatically when they are presented with pseudowords. We take inspiration from psycholinguistic experiments and develop question answering datasets that comprise of pseudowords - words that follow all the morphological and phonotactic rules of the language, but have no meaning. This allows us to evaluate how well large language models in various settings perform when given words that they are guaranteed to have no knowledge of, and benchmark their larger reasoning capabilities. *Equal Contribution.","p4":[],"RL":"In Preparation.","qv":"gostak.png"}'),c=a(184),l=(0,i.lazy)((function(){return Promise.resolve().then(a.bind(a,2478))})),h=(0,i.lazy)((function(){return a.e(333).then(a.bind(a,3333))})),d=(0,i.lazy)((function(){return Promise.all([a.e(58),a.e(301)]).then(a.bind(a,5301))})),p=function(){return(0,c.jsxs)(l,{children:[(0,c.jsx)(h,{}),(0,c.jsx)(d,{type:"left",title:s.TN,author:s.v,content:s.kQ,accept:s.RL,link:s.p4,icon:s.qv,id:"jabberwocky"}),(0,c.jsx)(d,{type:"left",title:n.TN,author:n.v,content:n.kQ,accept:n.RL,link:n.p4,icon:n.qv,id:"negative_transfer"}),(0,c.jsx)(d,{type:"left",title:o.TN,author:o.v,content:o.kQ,accept:o.RL,link:o.p4,icon:o.qv,id:"shape_bias"}),(0,c.jsx)(d,{type:"left",title:r.TN,author:r.v,content:r.kQ,accept:r.RL,link:r.p4,icon:r.qv,id:"alice"})]})}}}]);
//# sourceMappingURL=376.08bd31dc.chunk.js.map